{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from numpy import reshape\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION CODE</th>\n",
       "      <th>LOCATIONS</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Temp</th>\n",
       "      <th>D.O. (mg/l)</th>\n",
       "      <th>PH</th>\n",
       "      <th>CONDUCTIVITY (µmhos/cm)</th>\n",
       "      <th>B.O.D. (mg/l)</th>\n",
       "      <th>NITRATENAN N+ NITRITENANN (mg/l)</th>\n",
       "      <th>FECAL COLIFORM (MPN/100ml)</th>\n",
       "      <th>TOTAL COLIFORM (MPN/100ml)Mean</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1393</td>\n",
       "      <td>DAMANGANGA AT D/S OF MADHUBAN, DAMAN</td>\n",
       "      <td>DAMAN &amp; DIU</td>\n",
       "      <td>30.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>203</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1399</td>\n",
       "      <td>ZUARI AT D/S OF PT. WHERE KUMBARJRIA CANAL JOI...</td>\n",
       "      <td>GOA</td>\n",
       "      <td>29.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4953</td>\n",
       "      <td>8391</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1475</td>\n",
       "      <td>ZUARI AT PANCHAWADI</td>\n",
       "      <td>GOA</td>\n",
       "      <td>29.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>179</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3243</td>\n",
       "      <td>5330</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3181</td>\n",
       "      <td>RIVER ZUARI AT BORIM BRIDGE</td>\n",
       "      <td>GOA</td>\n",
       "      <td>29.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>64</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5382</td>\n",
       "      <td>8443</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3182</td>\n",
       "      <td>RIVER ZUARI AT MARCAIM JETTY</td>\n",
       "      <td>GOA</td>\n",
       "      <td>29.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>83</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3428</td>\n",
       "      <td>5500</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATION CODE                                          LOCATIONS  \\\n",
       "0         1393               DAMANGANGA AT D/S OF MADHUBAN, DAMAN   \n",
       "1         1399  ZUARI AT D/S OF PT. WHERE KUMBARJRIA CANAL JOI...   \n",
       "2         1475                                ZUARI AT PANCHAWADI   \n",
       "3         3181                        RIVER ZUARI AT BORIM BRIDGE   \n",
       "4         3182                       RIVER ZUARI AT MARCAIM JETTY   \n",
       "\n",
       "         STATE  Temp D.O. (mg/l)   PH CONDUCTIVITY (µmhos/cm) B.O.D. (mg/l)  \\\n",
       "0  DAMAN & DIU  30.6         6.7  7.5                     203           NAN   \n",
       "1          GOA  29.8         5.7  7.2                     189             2   \n",
       "2          GOA  29.5         6.3  6.9                     179           1.7   \n",
       "3          GOA  29.7         5.8  6.9                      64           3.8   \n",
       "4          GOA  29.5         5.8  7.3                      83           1.9   \n",
       "\n",
       "  NITRATENAN N+ NITRITENANN (mg/l) FECAL COLIFORM (MPN/100ml)  \\\n",
       "0                              0.1                         11   \n",
       "1                              0.2                       4953   \n",
       "2                              0.1                       3243   \n",
       "3                              0.5                       5382   \n",
       "4                              0.4                       3428   \n",
       "\n",
       "  TOTAL COLIFORM (MPN/100ml)Mean  year  \n",
       "0                             27  2014  \n",
       "1                           8391  2014  \n",
       "2                           5330  2014  \n",
       "3                           8443  2014  \n",
       "4                           5500  2014  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"water_dataX.csv\", encoding= 'unicode_escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION CODE                         object\n",
       "LOCATIONS                            object\n",
       "STATE                                object\n",
       "Temp                                float64\n",
       "D.O. (mg/l)                         float64\n",
       "PH                                  float64\n",
       "CONDUCTIVITY (µmhos/cm)             float64\n",
       "B.O.D. (mg/l)                       float64\n",
       "NITRATENAN N+ NITRITENANN (mg/l)    float64\n",
       "FECAL COLIFORM (MPN/100ml)          float64\n",
       "TOTAL COLIFORM (MPN/100ml)Mean      float64\n",
       "year                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conversions\n",
    "df['Temp']=pd.to_numeric(df['Temp'],errors='coerce')\n",
    "df['D.O. (mg/l)']=pd.to_numeric(df['D.O. (mg/l)'],errors='coerce')\n",
    "df['PH']=pd.to_numeric(df['PH'],errors='coerce')\n",
    "df['B.O.D. (mg/l)']=pd.to_numeric(df['B.O.D. (mg/l)'],errors='coerce')\n",
    "df['CONDUCTIVITY (µmhos/cm)']=pd.to_numeric(df['CONDUCTIVITY (µmhos/cm)'],errors='coerce')\n",
    "df['NITRATENAN N+ NITRITENANN (mg/l)']=pd.to_numeric(df['NITRATENAN N+ NITRITENANN (mg/l)'],errors='coerce')\n",
    "df['FECAL COLIFORM (MPN/100ml)']=pd.to_numeric(df['FECAL COLIFORM (MPN/100ml)'],errors='coerce')\n",
    "df['TOTAL COLIFORM (MPN/100ml)Mean']=pd.to_numeric(df['TOTAL COLIFORM (MPN/100ml)Mean'],errors='coerce')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization\n",
    "start=2\n",
    "end=1779\n",
    "station=df.iloc [start:end ,0]\n",
    "location=df.iloc [start:end ,1]\n",
    "state=df.iloc [start:end ,2]\n",
    "do= df.iloc [start:end ,4].astype(np.float64)\n",
    "value=0\n",
    "ph = df.iloc[ start:end,5]  \n",
    "co = df.iloc [start:end ,6].astype(np.float64)   \n",
    "  \n",
    "year=df.iloc[start:end,11]\n",
    "tc=df.iloc [2:end ,10].astype(np.float64)\n",
    "\n",
    "\n",
    "bod = df.iloc [start:end ,7].astype(np.float64)\n",
    "na= df.iloc [start:end ,8].astype(np.float64)\n",
    "na.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([station,location,state,do,ph,co,bod,na,tc],axis=1)\n",
    "df. columns = ['station','location','state','do','ph','co','bod','na','tc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station      object\n",
       "location     object\n",
       "state        object\n",
       "do          float64\n",
       "ph          float64\n",
       "co          float64\n",
       "bod         float64\n",
       "na          float64\n",
       "tc          float64\n",
       "npH           int64\n",
       "ndo           int64\n",
       "nco           int64\n",
       "nbdo          int64\n",
       "nec           int64\n",
       "nna           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['npH']=df.ph.apply(lambda x: (100 if (8.5>=x>=7)  \n",
    "                                 else(80 if  (8.6>=x>=8.5) or (6.9>=x>=6.8) \n",
    "                                      else(60 if (8.8>=x>=8.6) or (6.8>=x>=6.7) \n",
    "                                          else(40 if (9>=x>=8.8) or (6.7>=x>=6.5)\n",
    "                                              else 0)))))\n",
    "\n",
    "df['ndo']=df.do.apply(lambda x:(100 if (x>=6)  \n",
    "                                 else(80 if  (6>=x>=5.1) \n",
    "                                      else(60 if (5>=x>=4.1)\n",
    "                                          else(40 if (4>=x>=3) \n",
    "                                              else 0)))))\n",
    "\n",
    "df['nco']=df.tc.apply(lambda x:(100 if (5>=x>=0)  \n",
    "                                 else(80 if  (50>=x>=5) \n",
    "                                      else(60 if (500>=x>=50)\n",
    "                                          else(40 if (10000>=x>=500) \n",
    "                                              else 0)))))\n",
    "\n",
    "df['nbdo']=df.bod.apply(lambda x:(100 if (3>=x>=0)  \n",
    "                                 else(80 if  (6>=x>=3) \n",
    "                                      else(60 if (80>=x>=6)\n",
    "                                          else(40 if (125>=x>=80) \n",
    "                                              else 0)))))\n",
    "\n",
    "df['nec']=df.co.apply(lambda x:(100 if (75>=x>=0)  \n",
    "                                 else(80 if  (150>=x>=75) \n",
    "                                      else(60 if (225>=x>=150)\n",
    "                                          else(40 if (300>=x>=225) \n",
    "                                              else 0)))))\n",
    "df['nna']=df.na.apply(lambda x:(100 if (20>=x>=0)  \n",
    "                                 else(80 if  (50>=x>=20) \n",
    "                                      else(60 if (100>=x>=50)\n",
    "                                          else(40 if (200>=x>=100) \n",
    "                                              else 0)))))\n",
    "\n",
    "df.head()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wph']=df.npH * 0.165\n",
    "df['wdo']=df.ndo * 0.281\n",
    "df['wbdo']=df.nbdo * 0.234\n",
    "df['wec']=df.nec* 0.009\n",
    "df['wna']=df.nna * 0.028\n",
    "df['wco']=df.nco * 0.281\n",
    "df['wqi']=df.wph+df.wdo+df.wbdo+df.wec+df.wna+df.wco \n",
    "\n",
    "df['quality']=df.wqi.apply(lambda x:(1 if (75>=x>=0)  \n",
    "#                                  else('Good' if  (50>=x>=26) \n",
    "#                                       else('Poor' if (75>=x>=51)\n",
    "#                                           else('Very Poor' if (100>=x>=76) \n",
    "                                              else 0))#)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1138\n",
       "1     639\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station     0\n",
       "location    0\n",
       "state       0\n",
       "do          0\n",
       "ph          0\n",
       "co          0\n",
       "bod         0\n",
       "na          0\n",
       "tc          0\n",
       "npH         0\n",
       "ndo         0\n",
       "nco         0\n",
       "nbdo        0\n",
       "nec         0\n",
       "nna         0\n",
       "wph         0\n",
       "wdo         0\n",
       "wbdo        0\n",
       "wec         0\n",
       "wna         0\n",
       "wco         0\n",
       "wqi         0\n",
       "quality     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1495, 6) (1495,)\n"
     ]
    }
   ],
   "source": [
    "#input columns\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "\n",
    "input_cols1 = [\"npH\",\"ndo\",\"nbdo\",\"nec\",\"nna\",\"nco\"]\n",
    "X = df[input_cols1]\n",
    "y = df['wqi']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce41f05e48>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=7) #I have split this into 75-25 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 56        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,353\n",
      "Trainable params: 1,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "#                                             patience=3, \n",
    "#                                             verbose=1, \n",
    "#                                             factor=0.5, \n",
    "#                                             min_lr=0.000001)\n",
    "\n",
    "def ann_model():\n",
    "    ann = keras.models.Sequential()\n",
    "    \n",
    "    ann.add(Dense(8, input_dim=6,activation=\"relu\"))\n",
    "    \n",
    "    ann.add(Dense(16, activation=\"relu\"))\n",
    "    \n",
    "    ann.add(Dense(64, activation=\"relu\"))\n",
    "    ann.add(Dense(1))\n",
    "\n",
    "    ann.compile(optimizer='adam',loss = 'mse', metrics=['accuracy','mse'])\n",
    "    \n",
    "    return ann\n",
    "\n",
    "model = ann_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "38/38 [==============================] - 1s 9ms/step - loss: 2053.9968 - accuracy: 0.0000e+00 - mse: 2053.9968 - val_loss: 367.4347 - val_accuracy: 0.0000e+00 - val_mse: 367.4347\n",
      "Epoch 2/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 315.5633 - accuracy: 0.0000e+00 - mse: 315.5633 - val_loss: 248.4006 - val_accuracy: 0.0000e+00 - val_mse: 248.4006\n",
      "Epoch 3/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 223.5484 - accuracy: 0.0000e+00 - mse: 223.5484 - val_loss: 194.1905 - val_accuracy: 0.0000e+00 - val_mse: 194.1905\n",
      "Epoch 4/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 173.2987 - accuracy: 0.0000e+00 - mse: 173.2987 - val_loss: 142.2466 - val_accuracy: 0.0000e+00 - val_mse: 142.2466\n",
      "Epoch 5/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 108.8470 - accuracy: 0.0000e+00 - mse: 108.8470 - val_loss: 75.9969 - val_accuracy: 0.0000e+00 - val_mse: 75.9969\n",
      "Epoch 6/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 52.7205 - accuracy: 0.0000e+00 - mse: 52.7205 - val_loss: 37.6087 - val_accuracy: 0.0000e+00 - val_mse: 37.6087\n",
      "Epoch 7/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 29.6102 - accuracy: 0.0000e+00 - mse: 29.6102 - val_loss: 23.8713 - val_accuracy: 0.0000e+00 - val_mse: 23.8713\n",
      "Epoch 8/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 19.1082 - accuracy: 0.0000e+00 - mse: 19.1082 - val_loss: 17.8588 - val_accuracy: 0.0000e+00 - val_mse: 17.8588\n",
      "Epoch 9/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 13.8044 - accuracy: 0.0000e+00 - mse: 13.8044 - val_loss: 13.4413 - val_accuracy: 0.0000e+00 - val_mse: 13.4413\n",
      "Epoch 10/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 10.2393 - accuracy: 0.0000e+00 - mse: 10.2393 - val_loss: 10.2139 - val_accuracy: 0.0000e+00 - val_mse: 10.2139\n",
      "Epoch 11/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.5277 - accuracy: 0.0000e+00 - mse: 7.5277 - val_loss: 7.6491 - val_accuracy: 0.0000e+00 - val_mse: 7.6491\n",
      "Epoch 12/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 5.7682 - accuracy: 0.0000e+00 - mse: 5.7682 - val_loss: 5.7326 - val_accuracy: 0.0000e+00 - val_mse: 5.7326\n",
      "Epoch 13/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.4304 - accuracy: 0.0000e+00 - mse: 4.4304 - val_loss: 4.6679 - val_accuracy: 0.0000e+00 - val_mse: 4.6679\n",
      "Epoch 14/150\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 3.6651 - accuracy: 0.0000e+00 - mse: 3.6651 - val_loss: 3.7614 - val_accuracy: 0.0000e+00 - val_mse: 3.7614\n",
      "Epoch 15/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.1338 - accuracy: 0.0000e+00 - mse: 3.1338 - val_loss: 3.0981 - val_accuracy: 0.0000e+00 - val_mse: 3.0981\n",
      "Epoch 16/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8057 - accuracy: 0.0000e+00 - mse: 2.8057 - val_loss: 2.7022 - val_accuracy: 0.0000e+00 - val_mse: 2.7022\n",
      "Epoch 17/150\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 2.5651 - accuracy: 0.0000e+00 - mse: 2.5651 - val_loss: 2.3845 - val_accuracy: 0.0000e+00 - val_mse: 2.3845\n",
      "Epoch 18/150\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 2.3474 - accuracy: 0.0000e+00 - mse: 2.3474 - val_loss: 2.1348 - val_accuracy: 0.0000e+00 - val_mse: 2.1348\n",
      "Epoch 19/150\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 2.1909 - accuracy: 0.0000e+00 - mse: 2.1909 - val_loss: 1.8958 - val_accuracy: 0.0000e+00 - val_mse: 1.8958\n",
      "Epoch 20/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.0047 - accuracy: 0.0000e+00 - mse: 2.0047 - val_loss: 1.7166 - val_accuracy: 0.0000e+00 - val_mse: 1.7166\n",
      "Epoch 21/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.9252 - accuracy: 0.0000e+00 - mse: 1.9252 - val_loss: 1.5578 - val_accuracy: 0.0000e+00 - val_mse: 1.5578\n",
      "Epoch 22/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.7890 - accuracy: 0.0000e+00 - mse: 1.7890 - val_loss: 1.5958 - val_accuracy: 0.0000e+00 - val_mse: 1.5958\n",
      "Epoch 23/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7411 - accuracy: 0.0000e+00 - mse: 1.7411 - val_loss: 1.3884 - val_accuracy: 0.0000e+00 - val_mse: 1.3884\n",
      "Epoch 24/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.6841 - accuracy: 0.0000e+00 - mse: 1.6841 - val_loss: 1.3534 - val_accuracy: 0.0000e+00 - val_mse: 1.3534\n",
      "Epoch 25/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.6809 - accuracy: 0.0000e+00 - mse: 1.6809 - val_loss: 1.3417 - val_accuracy: 0.0000e+00 - val_mse: 1.3417\n",
      "Epoch 26/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5873 - accuracy: 0.0000e+00 - mse: 1.5873 - val_loss: 1.2425 - val_accuracy: 0.0000e+00 - val_mse: 1.2425\n",
      "Epoch 27/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5466 - accuracy: 0.0000e+00 - mse: 1.5466 - val_loss: 1.2264 - val_accuracy: 0.0000e+00 - val_mse: 1.2264\n",
      "Epoch 28/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5296 - accuracy: 0.0000e+00 - mse: 1.5296 - val_loss: 1.1362 - val_accuracy: 0.0000e+00 - val_mse: 1.1362\n",
      "Epoch 29/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4606 - accuracy: 0.0000e+00 - mse: 1.4606 - val_loss: 1.1850 - val_accuracy: 0.0000e+00 - val_mse: 1.1850\n",
      "Epoch 30/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4370 - accuracy: 0.0000e+00 - mse: 1.4370 - val_loss: 1.0823 - val_accuracy: 0.0000e+00 - val_mse: 1.0823\n",
      "Epoch 31/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3531 - accuracy: 0.0000e+00 - mse: 1.3531 - val_loss: 1.0601 - val_accuracy: 0.0000e+00 - val_mse: 1.0601\n",
      "Epoch 32/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3562 - accuracy: 0.0000e+00 - mse: 1.3562 - val_loss: 1.0501 - val_accuracy: 0.0000e+00 - val_mse: 1.0501\n",
      "Epoch 33/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3022 - accuracy: 0.0000e+00 - mse: 1.3022 - val_loss: 1.0878 - val_accuracy: 0.0000e+00 - val_mse: 1.0878\n",
      "Epoch 34/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2778 - accuracy: 0.0000e+00 - mse: 1.2778 - val_loss: 1.0108 - val_accuracy: 0.0000e+00 - val_mse: 1.0108\n",
      "Epoch 35/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.2825 - accuracy: 0.0000e+00 - mse: 1.2825 - val_loss: 0.9897 - val_accuracy: 0.0000e+00 - val_mse: 0.9897\n",
      "Epoch 36/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.0000e+00 - mse: 1.2147 - val_loss: 1.0962 - val_accuracy: 0.0000e+00 - val_mse: 1.0962\n",
      "Epoch 37/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1847 - accuracy: 0.0000e+00 - mse: 1.1847 - val_loss: 0.9279 - val_accuracy: 0.0000e+00 - val_mse: 0.9279\n",
      "Epoch 38/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1789 - accuracy: 0.0000e+00 - mse: 1.1789 - val_loss: 0.9357 - val_accuracy: 0.0000e+00 - val_mse: 0.9357\n",
      "Epoch 39/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.1033 - accuracy: 0.0000e+00 - mse: 1.1033 - val_loss: 0.9986 - val_accuracy: 0.0000e+00 - val_mse: 0.9986\n",
      "Epoch 40/150\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.1439 - accuracy: 0.0000e+00 - mse: 1.1439 - val_loss: 0.8991 - val_accuracy: 0.0000e+00 - val_mse: 0.8991\n",
      "Epoch 41/150\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 1.0512 - accuracy: 0.0000e+00 - mse: 1.0512 - val_loss: 0.8322 - val_accuracy: 0.0000e+00 - val_mse: 0.8322\n",
      "Epoch 42/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0078 - accuracy: 0.0000e+00 - mse: 1.0078 - val_loss: 0.7969 - val_accuracy: 0.0000e+00 - val_mse: 0.7969\n",
      "Epoch 43/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9999 - accuracy: 0.0000e+00 - mse: 0.9999 - val_loss: 0.8103 - val_accuracy: 0.0000e+00 - val_mse: 0.8103\n",
      "Epoch 44/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9680 - accuracy: 0.0000e+00 - mse: 0.9680 - val_loss: 0.8776 - val_accuracy: 0.0000e+00 - val_mse: 0.8776\n",
      "Epoch 45/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9341 - accuracy: 0.0000e+00 - mse: 0.9341 - val_loss: 0.8896 - val_accuracy: 0.0000e+00 - val_mse: 0.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8807 - accuracy: 0.0000e+00 - mse: 0.8807 - val_loss: 0.7951 - val_accuracy: 0.0000e+00 - val_mse: 0.7951\n",
      "Epoch 47/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8941 - accuracy: 0.0000e+00 - mse: 0.8941 - val_loss: 0.7596 - val_accuracy: 0.0000e+00 - val_mse: 0.7596\n",
      "Epoch 48/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8510 - accuracy: 0.0000e+00 - mse: 0.8510 - val_loss: 0.7055 - val_accuracy: 0.0000e+00 - val_mse: 0.7055\n",
      "Epoch 49/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8084 - accuracy: 0.0000e+00 - mse: 0.8084 - val_loss: 0.7736 - val_accuracy: 0.0000e+00 - val_mse: 0.7736\n",
      "Epoch 50/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8072 - accuracy: 0.0000e+00 - mse: 0.8072 - val_loss: 0.6872 - val_accuracy: 0.0000e+00 - val_mse: 0.6872\n",
      "Epoch 51/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8038 - accuracy: 0.0000e+00 - mse: 0.8038 - val_loss: 0.8585 - val_accuracy: 0.0000e+00 - val_mse: 0.8585\n",
      "Epoch 52/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7698 - accuracy: 0.0000e+00 - mse: 0.7698 - val_loss: 0.7210 - val_accuracy: 0.0000e+00 - val_mse: 0.7210\n",
      "Epoch 53/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7393 - accuracy: 0.0000e+00 - mse: 0.7393 - val_loss: 0.6494 - val_accuracy: 0.0000e+00 - val_mse: 0.6494\n",
      "Epoch 54/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7140 - accuracy: 0.0000e+00 - mse: 0.7140 - val_loss: 0.6203 - val_accuracy: 0.0000e+00 - val_mse: 0.6203\n",
      "Epoch 55/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7595 - accuracy: 0.0000e+00 - mse: 0.7595 - val_loss: 0.7579 - val_accuracy: 0.0000e+00 - val_mse: 0.7579\n",
      "Epoch 56/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7088 - accuracy: 0.0000e+00 - mse: 0.7088 - val_loss: 0.6295 - val_accuracy: 0.0000e+00 - val_mse: 0.6295\n",
      "Epoch 57/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6677 - accuracy: 0.0000e+00 - mse: 0.6677 - val_loss: 0.5924 - val_accuracy: 0.0000e+00 - val_mse: 0.5924\n",
      "Epoch 58/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6434 - accuracy: 0.0000e+00 - mse: 0.6434 - val_loss: 0.6293 - val_accuracy: 0.0000e+00 - val_mse: 0.6293\n",
      "Epoch 59/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.0000e+00 - mse: 0.6238 - val_loss: 0.5919 - val_accuracy: 0.0000e+00 - val_mse: 0.5919\n",
      "Epoch 60/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.0000e+00 - mse: 0.6268 - val_loss: 0.6430 - val_accuracy: 0.0000e+00 - val_mse: 0.6430\n",
      "Epoch 61/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.0000e+00 - mse: 0.6392 - val_loss: 0.6085 - val_accuracy: 0.0000e+00 - val_mse: 0.6085\n",
      "Epoch 62/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.0000e+00 - mse: 0.5955 - val_loss: 0.5646 - val_accuracy: 0.0000e+00 - val_mse: 0.5646\n",
      "Epoch 63/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.0000e+00 - mse: 0.5804 - val_loss: 0.5881 - val_accuracy: 0.0000e+00 - val_mse: 0.5881\n",
      "Epoch 64/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5878 - accuracy: 0.0000e+00 - mse: 0.5878 - val_loss: 0.7985 - val_accuracy: 0.0000e+00 - val_mse: 0.7985\n",
      "Epoch 65/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.0000e+00 - mse: 0.6114 - val_loss: 0.5631 - val_accuracy: 0.0000e+00 - val_mse: 0.5631\n",
      "Epoch 66/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5470 - accuracy: 0.0000e+00 - mse: 0.5470 - val_loss: 0.6110 - val_accuracy: 0.0000e+00 - val_mse: 0.6110\n",
      "Epoch 67/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5475 - accuracy: 0.0000e+00 - mse: 0.5475 - val_loss: 0.5496 - val_accuracy: 0.0000e+00 - val_mse: 0.5496\n",
      "Epoch 68/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5446 - accuracy: 0.0000e+00 - mse: 0.5446 - val_loss: 0.5562 - val_accuracy: 0.0000e+00 - val_mse: 0.5562\n",
      "Epoch 69/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.0000e+00 - mse: 0.4959 - val_loss: 0.5552 - val_accuracy: 0.0000e+00 - val_mse: 0.5552\n",
      "Epoch 70/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5048 - accuracy: 0.0000e+00 - mse: 0.5048 - val_loss: 0.5356 - val_accuracy: 0.0000e+00 - val_mse: 0.5356\n",
      "Epoch 71/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.0000e+00 - mse: 0.4926 - val_loss: 0.5527 - val_accuracy: 0.0000e+00 - val_mse: 0.5527\n",
      "Epoch 72/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.0000e+00 - mse: 0.4917 - val_loss: 0.5010 - val_accuracy: 0.0000e+00 - val_mse: 0.5010\n",
      "Epoch 73/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.0000e+00 - mse: 0.4563 - val_loss: 0.6787 - val_accuracy: 0.0000e+00 - val_mse: 0.6787\n",
      "Epoch 74/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.0000e+00 - mse: 0.4939 - val_loss: 0.4896 - val_accuracy: 0.0000e+00 - val_mse: 0.4896\n",
      "Epoch 75/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.0000e+00 - mse: 0.4699 - val_loss: 0.5277 - val_accuracy: 0.0000e+00 - val_mse: 0.5277\n",
      "Epoch 76/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.0000e+00 - mse: 0.4348 - val_loss: 0.5286 - val_accuracy: 0.0000e+00 - val_mse: 0.5286\n",
      "Epoch 77/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.0000e+00 - mse: 0.4401 - val_loss: 0.6180 - val_accuracy: 0.0000e+00 - val_mse: 0.6180\n",
      "Epoch 78/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.0000e+00 - mse: 0.4476 - val_loss: 0.4766 - val_accuracy: 0.0000e+00 - val_mse: 0.4766\n",
      "Epoch 79/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.0000e+00 - mse: 0.3949 - val_loss: 0.4770 - val_accuracy: 0.0000e+00 - val_mse: 0.4770\n",
      "Epoch 80/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.0000e+00 - mse: 0.3731 - val_loss: 0.4638 - val_accuracy: 0.0000e+00 - val_mse: 0.4638\n",
      "Epoch 81/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.0000e+00 - mse: 0.3774 - val_loss: 0.5964 - val_accuracy: 0.0000e+00 - val_mse: 0.5964\n",
      "Epoch 82/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.0000e+00 - mse: 0.3968 - val_loss: 0.4399 - val_accuracy: 0.0000e+00 - val_mse: 0.4399\n",
      "Epoch 83/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.0000e+00 - mse: 0.3533 - val_loss: 0.4274 - val_accuracy: 0.0000e+00 - val_mse: 0.4274\n",
      "Epoch 84/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.0000e+00 - mse: 0.3290 - val_loss: 0.4386 - val_accuracy: 0.0000e+00 - val_mse: 0.4386\n",
      "Epoch 85/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.0000e+00 - mse: 0.3286 - val_loss: 0.4382 - val_accuracy: 0.0000e+00 - val_mse: 0.4382\n",
      "Epoch 86/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.0000e+00 - mse: 0.3347 - val_loss: 0.4268 - val_accuracy: 0.0000e+00 - val_mse: 0.4268\n",
      "Epoch 87/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.0000e+00 - mse: 0.3178 - val_loss: 0.4122 - val_accuracy: 0.0000e+00 - val_mse: 0.4122\n",
      "Epoch 88/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3155 - accuracy: 0.0000e+00 - mse: 0.3155 - val_loss: 0.4600 - val_accuracy: 0.0000e+00 - val_mse: 0.4600\n",
      "Epoch 89/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.0000e+00 - mse: 0.2916 - val_loss: 0.4011 - val_accuracy: 0.0000e+00 - val_mse: 0.4011\n",
      "Epoch 90/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2754 - accuracy: 0.0000e+00 - mse: 0.2754 - val_loss: 0.3908 - val_accuracy: 0.0000e+00 - val_mse: 0.3908\n",
      "Epoch 91/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.0000e+00 - mse: 0.2671 - val_loss: 0.3780 - val_accuracy: 0.0000e+00 - val_mse: 0.3780\n",
      "Epoch 92/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2799 - accuracy: 0.0000e+00 - mse: 0.2799 - val_loss: 0.4153 - val_accuracy: 0.0000e+00 - val_mse: 0.4153\n",
      "Epoch 93/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2736 - accuracy: 0.0000e+00 - mse: 0.2736 - val_loss: 0.6097 - val_accuracy: 0.0000e+00 - val_mse: 0.6097\n",
      "Epoch 94/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3132 - accuracy: 0.0000e+00 - mse: 0.3132 - val_loss: 0.4070 - val_accuracy: 0.0000e+00 - val_mse: 0.4070\n",
      "Epoch 95/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2831 - accuracy: 0.0000e+00 - mse: 0.2831 - val_loss: 0.5529 - val_accuracy: 0.0000e+00 - val_mse: 0.5529\n",
      "Epoch 96/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2632 - accuracy: 0.0000e+00 - mse: 0.2632 - val_loss: 0.3958 - val_accuracy: 0.0000e+00 - val_mse: 0.3958\n",
      "Epoch 97/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2572 - accuracy: 0.0000e+00 - mse: 0.2572 - val_loss: 0.3653 - val_accuracy: 0.0000e+00 - val_mse: 0.3653\n",
      "Epoch 98/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2346 - accuracy: 0.0000e+00 - mse: 0.2346 - val_loss: 0.3929 - val_accuracy: 0.0000e+00 - val_mse: 0.3929\n",
      "Epoch 99/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2371 - accuracy: 0.0000e+00 - mse: 0.2371 - val_loss: 0.3650 - val_accuracy: 0.0000e+00 - val_mse: 0.3650\n",
      "Epoch 100/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2399 - accuracy: 0.0000e+00 - mse: 0.2399 - val_loss: 0.3448 - val_accuracy: 0.0000e+00 - val_mse: 0.3448\n",
      "Epoch 101/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2352 - accuracy: 0.0000e+00 - mse: 0.2352 - val_loss: 0.3238 - val_accuracy: 0.0000e+00 - val_mse: 0.3238\n",
      "Epoch 102/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2066 - accuracy: 0.0000e+00 - mse: 0.2066 - val_loss: 0.4031 - val_accuracy: 0.0000e+00 - val_mse: 0.4031\n",
      "Epoch 103/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2134 - accuracy: 0.0000e+00 - mse: 0.2134 - val_loss: 0.4355 - val_accuracy: 0.0000e+00 - val_mse: 0.4355\n",
      "Epoch 104/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2198 - accuracy: 0.0000e+00 - mse: 0.2198 - val_loss: 0.3366 - val_accuracy: 0.0000e+00 - val_mse: 0.3366\n",
      "Epoch 105/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2010 - accuracy: 0.0000e+00 - mse: 0.2010 - val_loss: 0.3515 - val_accuracy: 0.0000e+00 - val_mse: 0.3515\n",
      "Epoch 106/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1950 - accuracy: 0.0000e+00 - mse: 0.1950 - val_loss: 0.4410 - val_accuracy: 0.0000e+00 - val_mse: 0.4410\n",
      "Epoch 107/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.0000e+00 - mse: 0.3140 - val_loss: 0.3509 - val_accuracy: 0.0000e+00 - val_mse: 0.3509\n",
      "Epoch 108/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.0000e+00 - mse: 0.1869 - val_loss: 0.3216 - val_accuracy: 0.0000e+00 - val_mse: 0.3216\n",
      "Epoch 109/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.0000e+00 - mse: 0.1725 - val_loss: 0.3243 - val_accuracy: 0.0000e+00 - val_mse: 0.3243\n",
      "Epoch 110/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.0000e+00 - mse: 0.1966 - val_loss: 0.3381 - val_accuracy: 0.0000e+00 - val_mse: 0.3381\n",
      "Epoch 111/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.0000e+00 - mse: 0.1733 - val_loss: 0.2990 - val_accuracy: 0.0000e+00 - val_mse: 0.2990\n",
      "Epoch 112/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1806 - accuracy: 0.0000e+00 - mse: 0.1806 - val_loss: 0.2951 - val_accuracy: 0.0000e+00 - val_mse: 0.2951\n",
      "Epoch 113/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1715 - accuracy: 0.0000e+00 - mse: 0.1715 - val_loss: 0.3148 - val_accuracy: 0.0000e+00 - val_mse: 0.3148\n",
      "Epoch 114/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.0000e+00 - mse: 0.1594 - val_loss: 0.5021 - val_accuracy: 0.0000e+00 - val_mse: 0.5021\n",
      "Epoch 115/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1823 - accuracy: 0.0000e+00 - mse: 0.1823 - val_loss: 0.3097 - val_accuracy: 0.0000e+00 - val_mse: 0.3097\n",
      "Epoch 116/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1916 - accuracy: 0.0000e+00 - mse: 0.1916 - val_loss: 0.3413 - val_accuracy: 0.0000e+00 - val_mse: 0.3413\n",
      "Epoch 117/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1687 - accuracy: 0.0000e+00 - mse: 0.1687 - val_loss: 0.3029 - val_accuracy: 0.0000e+00 - val_mse: 0.3029\n",
      "Epoch 118/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.0000e+00 - mse: 0.1767 - val_loss: 0.2980 - val_accuracy: 0.0000e+00 - val_mse: 0.2980\n",
      "Epoch 119/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.0000e+00 - mse: 0.1911 - val_loss: 0.2820 - val_accuracy: 0.0000e+00 - val_mse: 0.2820\n",
      "Epoch 120/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - mse: 0.1428 - val_loss: 0.3099 - val_accuracy: 0.0000e+00 - val_mse: 0.3099\n",
      "Epoch 121/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.0000e+00 - mse: 0.1666 - val_loss: 0.2940 - val_accuracy: 0.0000e+00 - val_mse: 0.2940\n",
      "Epoch 122/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - mse: 0.1466 - val_loss: 0.3656 - val_accuracy: 0.0000e+00 - val_mse: 0.3656\n",
      "Epoch 123/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1697 - accuracy: 0.0000e+00 - mse: 0.1697 - val_loss: 0.3207 - val_accuracy: 0.0000e+00 - val_mse: 0.3207\n",
      "Epoch 124/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - mse: 0.1426 - val_loss: 0.2597 - val_accuracy: 0.0000e+00 - val_mse: 0.2597\n",
      "Epoch 125/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - mse: 0.1444 - val_loss: 0.2724 - val_accuracy: 0.0000e+00 - val_mse: 0.2724\n",
      "Epoch 126/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - mse: 0.1467 - val_loss: 0.2594 - val_accuracy: 0.0000e+00 - val_mse: 0.2594\n",
      "Epoch 127/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1238 - accuracy: 0.0000e+00 - mse: 0.1238 - val_loss: 0.3097 - val_accuracy: 0.0000e+00 - val_mse: 0.3097\n",
      "Epoch 128/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.0000e+00 - mse: 0.1263 - val_loss: 0.2480 - val_accuracy: 0.0000e+00 - val_mse: 0.2480\n",
      "Epoch 129/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - mse: 0.1344 - val_loss: 0.3318 - val_accuracy: 0.0000e+00 - val_mse: 0.3318\n",
      "Epoch 130/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.0000e+00 - mse: 0.1206 - val_loss: 0.2812 - val_accuracy: 0.0000e+00 - val_mse: 0.2812\n",
      "Epoch 131/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.0000e+00 - mse: 0.1293 - val_loss: 0.2618 - val_accuracy: 0.0000e+00 - val_mse: 0.2618\n",
      "Epoch 132/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.0000e+00 - mse: 0.1143 - val_loss: 0.2429 - val_accuracy: 0.0000e+00 - val_mse: 0.2429\n",
      "Epoch 133/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.0000e+00 - mse: 0.1141 - val_loss: 0.2645 - val_accuracy: 0.0000e+00 - val_mse: 0.2645\n",
      "Epoch 134/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.0000e+00 - mse: 0.1196 - val_loss: 0.2482 - val_accuracy: 0.0000e+00 - val_mse: 0.2482\n",
      "Epoch 135/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.0000e+00 - mse: 0.1058 - val_loss: 0.2310 - val_accuracy: 0.0000e+00 - val_mse: 0.2310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.0000e+00 - mse: 0.1057 - val_loss: 0.2406 - val_accuracy: 0.0000e+00 - val_mse: 0.2406\n",
      "Epoch 137/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.0000e+00 - mse: 0.1058 - val_loss: 0.2310 - val_accuracy: 0.0000e+00 - val_mse: 0.2310\n",
      "Epoch 138/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.0000e+00 - mse: 0.1236 - val_loss: 0.2196 - val_accuracy: 0.0000e+00 - val_mse: 0.2196\n",
      "Epoch 139/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.0000e+00 - mse: 0.1087 - val_loss: 0.2317 - val_accuracy: 0.0000e+00 - val_mse: 0.2317\n",
      "Epoch 140/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.0000e+00 - mse: 0.0971 - val_loss: 0.2221 - val_accuracy: 0.0000e+00 - val_mse: 0.2221\n",
      "Epoch 141/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.0000e+00 - mse: 0.1249 - val_loss: 0.2683 - val_accuracy: 0.0000e+00 - val_mse: 0.2683\n",
      "Epoch 142/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.0000e+00 - mse: 0.1192 - val_loss: 0.2509 - val_accuracy: 0.0000e+00 - val_mse: 0.2509\n",
      "Epoch 143/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1255 - accuracy: 0.0000e+00 - mse: 0.1255 - val_loss: 0.2269 - val_accuracy: 0.0000e+00 - val_mse: 0.2269\n",
      "Epoch 144/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.0000e+00 - mse: 0.1050 - val_loss: 0.2358 - val_accuracy: 0.0000e+00 - val_mse: 0.2358\n",
      "Epoch 145/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.0000e+00 - mse: 0.0991 - val_loss: 0.2186 - val_accuracy: 0.0000e+00 - val_mse: 0.2186\n",
      "Epoch 146/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1059 - accuracy: 0.0000e+00 - mse: 0.1059 - val_loss: 0.2083 - val_accuracy: 0.0000e+00 - val_mse: 0.2083\n",
      "Epoch 147/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0878 - accuracy: 0.0000e+00 - mse: 0.0878 - val_loss: 0.1933 - val_accuracy: 0.0000e+00 - val_mse: 0.1933\n",
      "Epoch 148/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1018 - accuracy: 0.0000e+00 - mse: 0.1018 - val_loss: 0.2033 - val_accuracy: 0.0000e+00 - val_mse: 0.2033\n",
      "Epoch 149/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0943 - accuracy: 0.0000e+00 - mse: 0.0943 - val_loss: 0.1847 - val_accuracy: 0.0000e+00 - val_mse: 0.1847\n",
      "Epoch 150/150\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.0000e+00 - mse: 0.0874 - val_loss: 0.1916 - val_accuracy: 0.0000e+00 - val_mse: 0.1916\n"
     ]
    }
   ],
   "source": [
    "#Declaring optimizers and learning rates for our models\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32, \n",
    "    epochs=150,\n",
    "    validation_data=(X_test,y_test)\n",
    "    #callbacks=[learning_rate_reduction]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72.75    ],\n",
       "       [89.02212 ],\n",
       "       [93.11901 ],\n",
       "       [87.57046 ],\n",
       "       [80.99615 ],\n",
       "       [82.47611 ],\n",
       "       [47.334106],\n",
       "       [71.660645],\n",
       "       [93.99777 ],\n",
       "       [65.326   ],\n",
       "       [88.286896],\n",
       "       [70.72262 ],\n",
       "       [82.47611 ],\n",
       "       [71.82942 ],\n",
       "       [78.56366 ],\n",
       "       [93.99777 ],\n",
       "       [83.361984],\n",
       "       [93.66865 ],\n",
       "       [81.88217 ],\n",
       "       [88.286896],\n",
       "       [60.787872],\n",
       "       [76.20211 ],\n",
       "       [82.9424  ],\n",
       "       [81.88217 ],\n",
       "       [82.9424  ],\n",
       "       [81.88217 ],\n",
       "       [88.57453 ],\n",
       "       [88.286896],\n",
       "       [82.9424  ],\n",
       "       [55.80135 ],\n",
       "       [79.04647 ],\n",
       "       [82.869385],\n",
       "       [82.47611 ],\n",
       "       [71.38624 ],\n",
       "       [85.26438 ],\n",
       "       [85.26438 ],\n",
       "       [72.93135 ],\n",
       "       [66.58059 ],\n",
       "       [82.47611 ],\n",
       "       [66.75686 ],\n",
       "       [67.15799 ],\n",
       "       [84.28714 ],\n",
       "       [93.99777 ],\n",
       "       [93.99777 ],\n",
       "       [77.873055],\n",
       "       [71.088394],\n",
       "       [84.89885 ],\n",
       "       [63.68297 ],\n",
       "       [82.869385],\n",
       "       [50.042934],\n",
       "       [73.80363 ],\n",
       "       [87.57046 ],\n",
       "       [78.56366 ],\n",
       "       [88.286896],\n",
       "       [93.11901 ],\n",
       "       [78.048485],\n",
       "       [77.88371 ],\n",
       "       [89.35723 ],\n",
       "       [93.07404 ],\n",
       "       [77.873055],\n",
       "       [83.666695],\n",
       "       [88.286896],\n",
       "       [87.57046 ],\n",
       "       [77.44632 ],\n",
       "       [79.45392 ],\n",
       "       [88.57453 ],\n",
       "       [73.0658  ],\n",
       "       [66.06715 ],\n",
       "       [81.88217 ],\n",
       "       [87.766014],\n",
       "       [38.040073],\n",
       "       [84.28714 ],\n",
       "       [79.59581 ],\n",
       "       [61.08951 ],\n",
       "       [93.99777 ],\n",
       "       [79.59581 ],\n",
       "       [84.89885 ],\n",
       "       [79.59581 ],\n",
       "       [66.25408 ],\n",
       "       [72.916046],\n",
       "       [82.47611 ],\n",
       "       [71.03131 ],\n",
       "       [84.28714 ],\n",
       "       [42.769768],\n",
       "       [79.59581 ],\n",
       "       [71.32618 ],\n",
       "       [78.17027 ],\n",
       "       [73.80363 ],\n",
       "       [83.361984],\n",
       "       [62.136044],\n",
       "       [75.70767 ],\n",
       "       [82.9424  ],\n",
       "       [76.12791 ],\n",
       "       [82.244644],\n",
       "       [93.99777 ],\n",
       "       [93.11901 ],\n",
       "       [70.79081 ],\n",
       "       [71.831566],\n",
       "       [81.88217 ],\n",
       "       [93.99777 ],\n",
       "       [55.80135 ],\n",
       "       [79.59581 ],\n",
       "       [87.57046 ],\n",
       "       [72.93135 ],\n",
       "       [67.020164],\n",
       "       [72.93135 ],\n",
       "       [69.96746 ],\n",
       "       [82.701866],\n",
       "       [82.9424  ],\n",
       "       [93.84142 ],\n",
       "       [87.57046 ],\n",
       "       [88.57453 ],\n",
       "       [47.334106],\n",
       "       [88.286896],\n",
       "       [88.57453 ],\n",
       "       [81.88217 ],\n",
       "       [82.47611 ],\n",
       "       [71.660645],\n",
       "       [82.701866],\n",
       "       [79.45392 ],\n",
       "       [72.93135 ],\n",
       "       [88.286896],\n",
       "       [78.54267 ],\n",
       "       [76.53629 ],\n",
       "       [81.88217 ],\n",
       "       [82.701866],\n",
       "       [85.26438 ],\n",
       "       [90.79655 ],\n",
       "       [50.042934],\n",
       "       [82.47611 ],\n",
       "       [81.1481  ],\n",
       "       [87.57046 ],\n",
       "       [46.676003],\n",
       "       [72.55909 ],\n",
       "       [77.360596],\n",
       "       [71.82942 ],\n",
       "       [76.32037 ],\n",
       "       [82.244644],\n",
       "       [84.28714 ],\n",
       "       [72.52955 ],\n",
       "       [82.9424  ],\n",
       "       [60.7639  ],\n",
       "       [88.286896],\n",
       "       [72.55909 ],\n",
       "       [93.99777 ],\n",
       "       [82.9424  ],\n",
       "       [82.869385],\n",
       "       [88.57453 ],\n",
       "       [19.429361],\n",
       "       [82.83926 ],\n",
       "       [67.020164],\n",
       "       [50.042934],\n",
       "       [55.80135 ],\n",
       "       [71.464775],\n",
       "       [50.042934],\n",
       "       [61.801167],\n",
       "       [76.32037 ],\n",
       "       [82.9424  ],\n",
       "       [79.05253 ],\n",
       "       [61.005604],\n",
       "       [81.82892 ],\n",
       "       [88.286896],\n",
       "       [71.088394],\n",
       "       [82.47611 ],\n",
       "       [88.286896],\n",
       "       [72.93135 ],\n",
       "       [76.12791 ],\n",
       "       [88.41793 ],\n",
       "       [79.59581 ],\n",
       "       [82.9424  ],\n",
       "       [75.17355 ],\n",
       "       [82.869385],\n",
       "       [89.02212 ],\n",
       "       [81.88217 ],\n",
       "       [66.06715 ],\n",
       "       [81.88217 ],\n",
       "       [71.82942 ],\n",
       "       [78.56366 ],\n",
       "       [74.1093  ],\n",
       "       [62.776142],\n",
       "       [83.666695],\n",
       "       [55.19867 ],\n",
       "       [88.286896],\n",
       "       [88.024925],\n",
       "       [89.83569 ],\n",
       "       [82.9424  ],\n",
       "       [79.64321 ],\n",
       "       [79.59581 ],\n",
       "       [93.97895 ],\n",
       "       [83.666695],\n",
       "       [82.701866],\n",
       "       [71.660645],\n",
       "       [81.88217 ],\n",
       "       [83.666695],\n",
       "       [77.164185],\n",
       "       [55.80135 ],\n",
       "       [83.666695],\n",
       "       [76.31709 ],\n",
       "       [93.11901 ],\n",
       "       [50.042934],\n",
       "       [84.28714 ],\n",
       "       [86.77422 ],\n",
       "       [32.858917],\n",
       "       [68.39042 ],\n",
       "       [82.869385],\n",
       "       [81.82892 ],\n",
       "       [67.020164],\n",
       "       [87.57046 ],\n",
       "       [87.57046 ],\n",
       "       [66.25408 ],\n",
       "       [31.037813],\n",
       "       [78.4089  ],\n",
       "       [43.97472 ],\n",
       "       [71.82942 ],\n",
       "       [76.20211 ],\n",
       "       [71.82942 ],\n",
       "       [82.244644],\n",
       "       [50.042934],\n",
       "       [72.75    ],\n",
       "       [55.02039 ],\n",
       "       [87.766014],\n",
       "       [83.81338 ],\n",
       "       [50.042934],\n",
       "       [78.56366 ],\n",
       "       [66.62036 ],\n",
       "       [88.286896],\n",
       "       [93.11901 ],\n",
       "       [43.92513 ],\n",
       "       [77.360596],\n",
       "       [88.286896],\n",
       "       [78.25571 ],\n",
       "       [79.59581 ],\n",
       "       [87.57046 ],\n",
       "       [72.55909 ],\n",
       "       [82.9424  ],\n",
       "       [88.286896],\n",
       "       [46.25145 ],\n",
       "       [75.17355 ],\n",
       "       [88.024925],\n",
       "       [43.97472 ],\n",
       "       [82.47611 ],\n",
       "       [77.319725],\n",
       "       [67.020164],\n",
       "       [60.87524 ],\n",
       "       [88.57453 ],\n",
       "       [93.11901 ],\n",
       "       [71.38624 ],\n",
       "       [89.17847 ],\n",
       "       [72.93135 ],\n",
       "       [73.80363 ],\n",
       "       [76.32037 ],\n",
       "       [78.56366 ],\n",
       "       [78.700066],\n",
       "       [50.042934],\n",
       "       [72.93135 ],\n",
       "       [72.93135 ],\n",
       "       [71.660645],\n",
       "       [82.9424  ],\n",
       "       [76.20211 ],\n",
       "       [70.72262 ],\n",
       "       [82.371254],\n",
       "       [81.9772  ],\n",
       "       [71.088394],\n",
       "       [21.287525],\n",
       "       [77.44632 ],\n",
       "       [83.666695],\n",
       "       [50.042934],\n",
       "       [80.83413 ],\n",
       "       [82.9424  ],\n",
       "       [82.244644],\n",
       "       [66.62036 ],\n",
       "       [78.701   ],\n",
       "       [83.361984],\n",
       "       [50.042934],\n",
       "       [84.89885 ],\n",
       "       [71.464775],\n",
       "       [55.80135 ],\n",
       "       [83.95921 ],\n",
       "       [83.666695],\n",
       "       [87.57046 ],\n",
       "       [76.20211 ],\n",
       "       [93.66865 ],\n",
       "       [79.04647 ],\n",
       "       [93.4138  ],\n",
       "       [77.319725],\n",
       "       [82.701866],\n",
       "       [88.286896],\n",
       "       [77.319725],\n",
       "       [71.660645],\n",
       "       [61.23256 ],\n",
       "       [88.024925],\n",
       "       [77.873055],\n",
       "       [88.57453 ],\n",
       "       [76.07681 ],\n",
       "       [84.28714 ],\n",
       "       [87.57046 ],\n",
       "       [61.523945],\n",
       "       [88.57453 ],\n",
       "       [78.17027 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.0000e+00 - mse: 0.1916\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "epochs = range(1, len(loss)+1)\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
